{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryo/.pyenv/versions/3.12.5/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ryo/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from transformers import PreTrainedModel, AutoModel, LlamaModel, AutoTokenizer\n",
    "from transformers.file_utils import ModelOutput\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "\n",
    "from data import HFTrainDataset, TrainDataset, TrainCollator\n",
    "from tevatron.arguments import ModelArguments, DataArguments, \\\n",
    "    TevatronTrainingArguments as TrainingArguments\n",
    "from trainer import TevatronTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EncoderOutput(ModelOutput):\n",
    "    q_reps: Optional[Tensor] = None\n",
    "    p_reps: Optional[Tensor] = None\n",
    "    loss: Optional[Tensor] = None\n",
    "    scores: Optional[Tensor] = None\n",
    "\n",
    "\n",
    "class EncoderModel(nn.Module):\n",
    "    def __init__(self, lm_q: PreTrainedModel, lm_p: PreTrainedModel, pooler: nn.Module=None):\n",
    "        super(EncoderModel, self).__init__()\n",
    "\n",
    "        self.lm_q = lm_q\n",
    "        self.lm_p = lm_p\n",
    "        self.pooler = pooler\n",
    "        self.cross_entropy = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "    def forward(self, query: Dict[str, Tensor] = None, passage: Dict[str, Tensor] = None):\n",
    "        q_reps = self.encode_query(query)\n",
    "        p_reps = self.encode_passage(passage)\n",
    "        loss = None\n",
    "        scores = None\n",
    "\n",
    "        # traingin\n",
    "        if self.training:\n",
    "            scores = self.compute_similarity(q_reps, p_reps)\n",
    "\n",
    "            # 類似度スコアのテンソルをクエリごとの類似度スコアの行列に整形し直す\n",
    "            # (クエリの数, パッセージの数 / クエリの数)\n",
    "            scores = scores.view(q_reps.size(0), -1)\n",
    "\n",
    "            # クエリごとの正解ラベルを整形し直す\n",
    "            # クエリに対して関連するパッセージの分だけインデックスを調整\n",
    "            target = torch.arange(scores.size(0), device=scores.device, dtype=torch.long)\n",
    "            target = target * (p_reps.size(0) // query_size)\n",
    "\n",
    "            loss = self.compute_loss(scores, target)\n",
    "\n",
    "        return EncoderOutput(\n",
    "            loss=loss,\n",
    "            scores=scores,\n",
    "            q_reps=q_reps,\n",
    "            p_reps=p_reps,\n",
    "        )\n",
    "\n",
    "    def encode_passage(self, passage):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode_query(self, query):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def compute_similarity(self, q_reps, p_reps):\n",
    "        return torch.matmul(q_reps, p_reps.transpose(0, 1))\n",
    "\n",
    "    def comupte_loss(self, scores, target):\n",
    "        raise self.cross_entropy(scores, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepLLaMA(EncoderModel):\n",
    "    def __init__(self, lm_q: PreTrainedModel, lm_p: PreTrainedModel, pooler: nn.Module=None):\n",
    "        super(RepLLaMA, self).__init__(lm_q, lm_p, pooler)\n",
    "\n",
    "    def encode_passage(self, passage):\n",
    "        if passage is None:\n",
    "            return None\n",
    "\n",
    "        passage_output = self.lm_p(**passage, output_hidden_states=True)\n",
    "        p_hidden = passage_output.hidden_states[-1]\n",
    "        attention_mask = passage[\"attention_mask\"]\n",
    "\n",
    "        # paddingではない最後のトークンに対応する埋め込み表現を取得\n",
    "        ## 行ごとにpaddingされていない部分=実際のトークンの数を集計\n",
    "        sequence_lengths = attention_mask.sum(dim=1)\n",
    "        last_token_indices = sequence_lengths - 1\n",
    "\n",
    "        ## バッチ内の各系列の隠れ層の出力\n",
    "        ### p_hidden: (batch_size, seq_len, hidden_size)\n",
    "        p_reps = p_hidden[torch.arange(p_hidden.size(0)), last_token_indices]\n",
    "        p_reps = nn.functional.normalize(p_reps, p=2, dim=-1)\n",
    "        return p_reps\n",
    "\n",
    "    def encode_query(self, query):\n",
    "        if query is None:\n",
    "            return None\n",
    "\n",
    "        query_output = self.lm_q(**query, output_hidden_states=True)\n",
    "        q_hidden = query_output.hidden_states[-1]\n",
    "        attention_mask = query[\"attention_mask\"]\n",
    "\n",
    "        # paddingではない最後のトークンに対応する埋め込み表現を取得\n",
    "        ## 行ごとにpaddingされていない部分=実際のトークンの数を集計\n",
    "        sequence_lengths = attention_mask.sum(dim=1)\n",
    "        last_token_indices = sequence_lengths - 1\n",
    "\n",
    "        ## バッチ内の各系列の隠れ層の出力\n",
    "        ### q_hidden: (batch_size, seq_len, hidden_size)\n",
    "        q_reps = q_hidden[torch.arange(q_hidden.size(0)), last_token_indices]\n",
    "        q_reps = nn.functional.normalize(q_reps, p=2, dim=-1)\n",
    "        return q_reps\n",
    "\n",
    "    def gradient_checkpointing_enable(self, **kwargs):\n",
    "        return self.lm_q.base_model.gradient_checkpointing_enable()\n",
    "\n",
    "    # いる？？\n",
    "    @staticmethod\n",
    "    def build_peft_model(peft_model_name: str):\n",
    "        config = LoraConfig.from_pretrained(peft_model_name)\n",
    "        config.inference_mode = False\n",
    "        base_model = LlamaModel.from_pretrained(config.base_model_name_or_path)\n",
    "        model = get_peft_model(base_model, config)\n",
    "        model.print_trainable_parameters()\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def build(cls, model_config, train_config, **hf_kwargs):\n",
    "        base_model = LlamaModel.from_pretrained(model_config.model_name_or_path, **hf_kwargs)\n",
    "\n",
    "        if train_config.gradient_checkpointing:\n",
    "            base_model.gradient_checkpointing_enable()\n",
    "\n",
    "        if base_model.config.pad_token_id is None:\n",
    "            base_model.config.pad_token_id = 0\n",
    "\n",
    "\n",
    "        peft_config = LoraConfig(\n",
    "            base_model_name_or_path=model_config.model_name_or_path,\n",
    "            task_type=TaskType.FEATURE_EXTRACTION,\n",
    "            r=32,\n",
    "            lora_alpha=64,\n",
    "            lora_dropout=0.1,\n",
    "            target_modules=[\"q_proj\", \"v_proj\", \"o_proj\", \"down_proj\", \"up_proj\", \"gate_proj\"],\n",
    "            inference_mode=False\n",
    "        )\n",
    "\n",
    "        hf_model = get_peft_model(base_model, peft_config)\n",
    "        model = cls(\n",
    "            lm_q=hf_model,\n",
    "            lm_p=hf_model,\n",
    "            pooler=None,  \n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def save(self, output_dir):\n",
    "        self.lm_q.save_pretrained(output_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name_or_path=\"meta-llama/Llama-3.2-1B\"\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "    dataset_name=\"Tevatron/msmarco-passage\",\n",
    "    train_n_passages=16,\n",
    "    q_max_len=32,\n",
    "    p_max_len=128,\n",
    "    dataset_proc_num=32\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"model_repllama\",\n",
    "    save_steps=20,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_steps=10,\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir\n",
    ")\n",
    "tokenizer.pad_token_id = tokenizer.unk_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RepLLaMA.__init__() takes 1 positional argument but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRepLLaMA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 78\u001b[0m, in \u001b[0;36mRepLLaMA.build\u001b[0;34m(cls, model_config, train_config, **hf_kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[1;32m     68\u001b[0m     base_model_name_or_path\u001b[38;5;241m=\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmodel_name_or_path,\n\u001b[1;32m     69\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mFEATURE_EXTRACTION,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m     inference_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m hf_model \u001b[38;5;241m=\u001b[39m get_peft_model(base_model, peft_config)\n\u001b[0;32m---> 78\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlm_q\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlm_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mRepLLaMA.__init__\u001b[0;34m(self, lm_q, lm_p, pooler)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lm_q: PreTrainedModel, lm_p: PreTrainedModel, pooler: nn\u001b[38;5;241m.\u001b[39mModule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRepLLaMA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m, in \u001b[0;36mEncoderModel.__init__\u001b[0;34m(self, lm_q, lm_p, pooler)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lm_q: PreTrainedModel, lm_p: PreTrainedModel, pooler: nn\u001b[38;5;241m.\u001b[39mModule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mEncoderModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlm_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_q \u001b[38;5;241m=\u001b[39m lm_q\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_p \u001b[38;5;241m=\u001b[39m lm_p\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/torch/nn/modules/module.py:439\u001b[0m, in \u001b[0;36mModule.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: RepLLaMA.__init__() takes 1 positional argument but 4 were given"
     ]
    }
   ],
   "source": [
    "model = RepLLaMA.build(\n",
    "    model_args,\n",
    "    training_args,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on train dataset (num_proc=32): 100%|██████████| 400782/400782 [02:56<00:00, 2272.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HFTrainDataset(\n",
    "    tokenizer=tokenizer, \n",
    "    data_args=data_args,\n",
    "    cache_dir=data_args.data_cache_dir or model_args.cache_dir\n",
    ")\n",
    "train_dataset = TrainDataset(data_args, train_dataset.process(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TevatronTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=TrainCollator(\n",
    "        tokenizer,\n",
    "        max_p_len=data_args.p_max_len,\n",
    "        max_q_len=data_args.q_max_len\n",
    "    ),\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'target' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/trainer.py:2388\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2387\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2388\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2391\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2392\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2393\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2394\u001b[0m ):\n\u001b[1;32m   2395\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2396\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/dev/dense_retrieval/dense_retrieval/trainer.py:55\u001b[0m, in \u001b[0;36mTevatronTrainer.training_step\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTevatronTrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dist_loss_scale_factor\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/transformers/trainer.py:3485\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3485\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3490\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3491\u001b[0m ):\n",
      "File \u001b[0;32m~/dev/dense_retrieval/dense_retrieval/trainer.py:52\u001b[0m, in \u001b[0;36mTevatronTrainer.compute_loss\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs):\n\u001b[1;32m     51\u001b[0m     query, passage \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpassage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/accelerate/utils/operations.py:820\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/accelerate/utils/operations.py:808\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.5/lib/python3.12/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mEncoderModel.forward\u001b[0;34m(self, query, passage)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# クエリごとの正解ラベルを整形し直す\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# クエリに対して関連するパッセージの分だけインデックスを調整\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     taregt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(scores\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), device\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m---> 36\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m \u001b[38;5;241m*\u001b[39m (p_reps\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m query_size)\n\u001b[1;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(scores, target)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m EncoderOutput(\n\u001b[1;32m     41\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m     42\u001b[0m     scores\u001b[38;5;241m=\u001b[39mscores,\n\u001b[1;32m     43\u001b[0m     q_reps\u001b[38;5;241m=\u001b[39mq_reps,\n\u001b[1;32m     44\u001b[0m     p_reps\u001b[38;5;241m=\u001b[39mp_reps,\n\u001b[1;32m     45\u001b[0m )\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'target' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "train_dataset.trainer = trainer\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
